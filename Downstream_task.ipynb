{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "s9MtD2NtnK5p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23843,
     "status": "ok",
     "timestamp": 1716580125496,
     "user": {
      "displayName": "Juhyeon Lee",
      "userId": "10677926440039300953"
     },
     "user_tz": 240
    },
    "id": "s9MtD2NtnK5p",
    "outputId": "19a3cfc5-6c1d-416c-9576-c04add3fbf60"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from itertools import tee\n",
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import yaml\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import r2_score, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import linregress, pearsonr\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import f as f_oneway\n",
    "\n",
    "from datautils import load_ftn\n",
    "from contrastive_model import ContrastiveModel\n",
    "from utils import init_dl_program\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# to make pdf fonts in vector\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"colorblind\")\n",
    "sns.set_context('paper')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = False  # Turn off histogram borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc04359-37e2-43b1-843f-a03285fb82db",
   "metadata": {
    "id": "4bc04359-37e2-43b1-843f-a03285fb82db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def utest_with_effect(g1: np.ndarray, g2: np.ndarray):\n",
    "    n1, n2 = len(g1), len(g2)\n",
    "    u1, p = mannwhitneyu(g1, g2)\n",
    "    u2 = n1 * n2 - u1\n",
    "    f = u1 / (n1 * n2)  # Common language effect size; eq. to AUROC\n",
    "    return u1, u2, f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b42533ae-eb59-45df-9840-6532e3322214",
   "metadata": {
    "id": "b42533ae-eb59-45df-9840-6532e3322214"
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "\n",
    "def plot_results(gt_list, res_list, sub_list, diag_list_sub, label_predict, seg_len):\n",
    "    \"\"\"\n",
    "    Generates and visualizes evaluation results for regression downstream tasks.\n",
    "\n",
    "    Parameters:\n",
    "    - gt_list (array-like): clinician scores.\n",
    "    - res_list (array-like): Estimated scores from the model.\n",
    "    - sub_list (array-like): List of subject identifiers and dates.\n",
    "    - diag_list_sub (array-like): Diagnosis information for each subject (1 for ataxia, 0 for healthy).\n",
    "    - label_predict (str): Label indicating the type of score being predicted.\n",
    "    - seg_len (int): Segment length used in the evaluation.\n",
    "\n",
    "    Returns:\n",
    "    - r2 (float): R-squared value for cross-sectional evaluation.\n",
    "    - rmse (float): Root Mean Squared Error for cross-sectional evaluation.\n",
    "    - long_r (float): Pearson correlation coefficient for longitudinal evaluation.\n",
    "    - long_p (float): p-value for longitudinal evaluation.\n",
    "    \"\"\"\n",
    "    # Calculate evaluation metrics (R-squared, RMSE, Pearson correlation)\n",
    "    r2 = r2_score(gt_list, res_list)\n",
    "    rmse = np.sqrt(np.mean(np.square(gt_list - res_list)))\n",
    "    cross_r, cross_p = pearsonr(gt_list, res_list)\n",
    "\n",
    "    # Initialize variables to hold longitudinal analysis data\n",
    "    date_diff, gt_diff, pred_diff, baseline, date_list = [], [], [], [], []\n",
    "    detected = set()\n",
    "\n",
    "    # Iterate over subjects and compute longitudinal differences\n",
    "    for s in sub_list:\n",
    "        date_list.append(np.datetime64('-'.join(s[6:].split('_'))))\n",
    "        subject_id = s[:5]\n",
    "        if subject_id not in detected:\n",
    "            detected.add(subject_id)\n",
    "            sub_same_ind = np.char.find(sub_list, subject_id) != -1\n",
    "            if np.sum(sub_same_ind) >= 2:\n",
    "                for (x1, y1, d1), (x2, y2, d2) in pairwise(zip(gt_list[sub_same_ind], res_list[sub_same_ind], sub_list[sub_same_ind])):\n",
    "                    if diag_list_sub[sub_same_ind][0] != 0:\n",
    "                        gt_diff.append(x2 - x1)\n",
    "                        pred_diff.append(y2 - y1)\n",
    "                        d2_date = np.datetime64('-'.join(d2[6:].split('_')))\n",
    "                        d1_date = np.datetime64('-'.join(d1[6:].split('_')))\n",
    "                        baseline.append(x1)\n",
    "                        date_diff.append((d2_date - d1_date).astype('float'))\n",
    "\n",
    "    gt_diff, pred_diff = np.array(gt_diff), np.array(pred_diff)\n",
    "\n",
    "\n",
    "    # Create subplots for cross-sectional and longitudinal analysis\n",
    "    fig, (fig_cross, fig_long) = plt.subplots(1, 2, figsize=(9, 4))\n",
    "    fig_cross.scatter(gt_list[diag_list_sub == 1], res_list[diag_list_sub == 1], c='b', label='Ataxia')\n",
    "    fig_cross.scatter(gt_list[diag_list_sub == 0], res_list[diag_list_sub == 0], c='g', label='Healthy')\n",
    "    \n",
    "    # Plot cross-sectional evaluation (scatter plot)\n",
    "    min_val, max_val = min(np.min(res_list), np.min(gt_list)), max(np.max(res_list), np.max(gt_list))\n",
    "    res = linregress(gt_list, res_list)\n",
    "    fig_cross.plot([min_val - 0.5, max_val + 0.5], [res.intercept + res.slope * (min_val - 0.5), res.intercept + res.slope * (max_val + 0.5)], 'k--')\n",
    "    fig_cross.plot([min_val - 0.5, max_val + 0.5], [min_val - 0.5, max_val + 0.5], 'k')\n",
    "    fig_cross.set_xlabel(f'Clinician-scored {label_predict}')\n",
    "    fig_cross.set_ylabel(f'Estimated {label_predict}')\n",
    "    fig_cross.axis('square')\n",
    "    fig_cross.legend()\n",
    "\n",
    "    # Plot longitudinal evaluation (scatter plot)\n",
    "    min_y, max_y = min(np.min(gt_diff), np.min(pred_diff)), max(np.max(gt_diff), np.max(pred_diff))\n",
    "    cb = fig_long.scatter(gt_diff, pred_diff, c=baseline, cmap='viridis', vmin=np.min(gt_list), vmax=np.max(gt_list))\n",
    "    res_diff = linregress(gt_diff, pred_diff)\n",
    "    fig_long.plot([min_y - 0.5, max_y + 0.5], [res_diff.intercept + res_diff.slope * (min_y - 0.5), res_diff.intercept + res_diff.slope * (max_y + 0.5)], 'k--')\n",
    "    fig_long.plot([min_y - 0.5, max_y + 0.5], [min_y - 0.5, max_y + 0.5], 'k')\n",
    "    fig_long.set_xlabel(f'Diff. Clinician-scored {label_predict}')\n",
    "    fig_long.set_ylabel(f'Diff. Estimated {label_predict}')\n",
    "    fig_long.set_aspect('equal')\n",
    "    fig_long.axvline(0, linestyle='--', color='r')\n",
    "    fig_long.axhline(0, linestyle='--', color='r')\n",
    "    clb = plt.colorbar(cb, ax=fig_long)\n",
    "    clb.ax.tick_params(labelsize=8)\n",
    "    clb.set_label('Clinician-scored Total BARS (Baseline)', rotation=270, fontsize=8, labelpad=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_folder_name}/results_{label_predict}_{seg_len}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate and print longitudinal Pearson correlation\n",
    "    long_r, long_p = pearsonr(gt_diff, pred_diff)\n",
    "    print(f'Cross-Sectional R2: {r2:.2f}, RMSE: {rmse:.2f}, Pearson r: {cross_r:.2f}, p: {cross_p:.3f} /  Longitudinal r: {long_r:.2f}, p: {long_p:.3f}')\n",
    "\n",
    "    return r2, rmse, cross_r, cross_p, long_r, long_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201d3544-4d46-452f-882a-94cefd0ed65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "        cfg = yaml.safe_load(file)\n",
    "\n",
    "run_name = cfg.get('run_name', 'ftn_no_rotate')\n",
    "gpu = cfg.get('gpu', '0')\n",
    "batch_size = cfg.get('batch_size', 32)\n",
    "lr = cfg.get('lr', 0.001)\n",
    "repr_dims = cfg.get('repr_dims', 320)\n",
    "epochs = cfg.get('epochs', 200)\n",
    "seed = cfg.get('seed', 42)\n",
    "max_threads = cfg.get('max_threads', 8)\n",
    "freq = cfg.get('freq', 128)\n",
    "seg_length_sec = cfg.get('seg_length_sec', 10)\n",
    "cv_num = cfg.get('cv_num', 5)\n",
    "seg_length = freq * seg_length_sec\n",
    "\n",
    "save_folder_name = 'mean_embeddings_random_rotall'\n",
    "model_folder_name = 'seglen_performance_random_rotall'\n",
    "\n",
    "seg_length_list = []\n",
    "file_list = np.array(os.listdir(model_folder_name))\n",
    "for files in file_list:\n",
    "    if \".\" not in files:\n",
    "        seg_length_list.append(int(files.split('_')[-1]))\n",
    "    else:\n",
    "        seg_length_list.append(np.nan)\n",
    "seg_length_list = np.array(seg_length_list)\n",
    "file_list = file_list[~np.isnan(seg_length_list)]\n",
    "seg_length_list = seg_length_list[~np.isnan(seg_length_list)]\n",
    "seg_length_idx = np.argsort(seg_length_list)\n",
    "seg_length_list = seg_length_list[seg_length_idx]\n",
    "file_list = file_list[seg_length_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb0aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'r2': [],\n",
    "    'rmse': [],\n",
    "    'cross_corr': [],\n",
    "    'cross_pval': [],\n",
    "    'longitudinal_corr': [],\n",
    "    'longitudinal_pval': [],\n",
    "    'auc': []\n",
    "}\n",
    "\n",
    "def store_metrics(metrics, r2, rmse, cross_r, cross_p, long_r, long_p, auc):\n",
    "    metrics['r2'].append(r2)\n",
    "    metrics['rmse'].append(rmse)\n",
    "    metrics['cross_corr'].append(cross_r)\n",
    "    metrics['cross_pval'].append(cross_p)\n",
    "    metrics['longitudinal_corr'].append(long_r)\n",
    "    metrics['longitudinal_pval'].append(long_p)\n",
    "    metrics['auc'].append(auc)\n",
    "\n",
    "def compute_auc(gt_cl_list, pred_cl_list, diag_list_sub, gt_arm_list):\n",
    "    fpr, tpr, _ = roc_curve(gt_cl_list, pred_cl_list)\n",
    "    fpr_armz, tpr_armz, _ = roc_curve(gt_cl_list[np.logical_or(np.logical_and(diag_list_sub != 0, gt_arm_list == 0), diag_list_sub == 0)], \n",
    "                                              pred_cl_list[np.logical_or(np.logical_and(diag_list_sub != 0, gt_arm_list == 0), diag_list_sub == 0)])\n",
    "    auc_arm_z = utest_with_effect(pred_cl_list[np.logical_and(diag_list_sub != 0, gt_arm_list == 0)], pred_cl_list[diag_list_sub == 0])[2]\n",
    "    print(utest_with_effect(pred_cl_list[diag_list_sub != 0], pred_cl_list[diag_list_sub == 0]))\n",
    "    print(utest_with_effect(pred_cl_list[np.logical_and(diag_list_sub != 0, gt_arm_list == 0)], pred_cl_list[diag_list_sub == 0]))\n",
    "\n",
    "    auc = roc_auc_score(gt_cl_list, pred_cl_list)\n",
    "    fig_cl = plt.figure(figsize=(8, 4))\n",
    "    ax = fig_cl.add_subplot(1, 2, 1)\n",
    "    ax.plot(fpr, tpr, label=\"AUC = {:.2}\".format(auc))\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    ax = fig_cl.add_subplot(1, 2, 2)\n",
    "    ax.plot(fpr_armz, tpr_armz, label=\"AUC = {:.2}\".format(auc_arm_z))\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_folder_name + '/cl_results_{}.pdf'.format(seg_length))\n",
    "    plt.show()\n",
    "    return auc\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "503d67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svr(X_train, y_train):\n",
    "    grid_search = GridSearchCV(SVR(), {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], 'kernel': ['rbf'], 'gamma': ['scale']}, cv=10, n_jobs=4)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "\n",
    "def train_svc(X_train, y_train):\n",
    "    grid_search = GridSearchCV(SVC(probability=True), {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], 'kernel': ['rbf'], 'gamma': ['scale']}, cv=10, n_jobs=4)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e261dc-cd2f-48bf-9384-b484b69636f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "15iR3jYW0jKQ8dCWI1Gt__TtInN0v8FJd"
    },
    "executionInfo": {
     "elapsed": 811683,
     "status": "ok",
     "timestamp": 1716435766102,
     "user": {
      "displayName": "Juhyeon Lee",
      "userId": "10677926440039300953"
     },
     "user_tz": 240
    },
    "id": "e0e261dc-cd2f-48bf-9384-b484b69636f9",
    "outputId": "f907b0c2-2e5a-4314-9152-5b77bd19564b"
   },
   "outputs": [],
   "source": [
    "\n",
    "for files in file_list:\n",
    "    seg_length = int(files.split('_')[-1])\n",
    "    print(seg_length, seg_length / freq)\n",
    "    if (seg_length/ freq) > 20:\n",
    "        break\n",
    "\n",
    "    device = init_dl_program('cpu', seed=seed, max_threads=8, deterministic=False)\n",
    "    train_set = load_ftn(cv_num, seg_length, is_train=True)\n",
    "\n",
    "    device = init_dl_program('cpu', seed=seed, max_threads=8, deterministic=False)\n",
    "    test_set = load_ftn(cv_num, seg_length, is_train=False, overlap_test=seg_length)\n",
    "\n",
    "    sub_list = []\n",
    "    diag_list = []\n",
    "    gt_list = []\n",
    "    gt_arm_list = []\n",
    "    gt_l_list = []\n",
    "    gt_r_list = []\n",
    "    gt_cl_list = []\n",
    "    pred_list = []\n",
    "    pred_l_list = []\n",
    "    pred_r_list = []\n",
    "    pred_cl_list = []\n",
    "    pred_first_list = []\n",
    "    pred_second_list = []\n",
    "    pred_arm_list = []\n",
    "    non_lr_list = []\n",
    "    non_ts_list = []\n",
    "    embed_pca_list = []\n",
    "    age_list = []\n",
    "    pred_variability = []\n",
    "    all_test_embed = []\n",
    "    \n",
    "    fig_pca = plt.figure(figsize = (18, 3))\n",
    "    for cv in range(cv_num):\n",
    "        model = ContrastiveModel(\n",
    "            input_dims=train_set[cv]['data'].shape[-1],\n",
    "            device=device,\n",
    "        )\n",
    "        train_sub_date = train_set[cv]['sub_date']\n",
    "        test_sub_date = test_set[cv]['sub_date']\n",
    "        test_arm = test_set[cv]['arm']\n",
    "        \n",
    "        # Load the trained model\n",
    "        model.load(os.path.join(model_folder_name, files, 'model_{}.pkl'.format(cv)))\n",
    "\n",
    "        # Encode representations\n",
    "        train_repr = model.encode(train_set[cv]['data'], encoding_window='full_series', batch_size=128)\n",
    "        test_repr = model.encode(test_set[cv]['data'], encoding_window='full_series', batch_size=128)\n",
    "\n",
    "        # aggregate represensetions for each subject and session\n",
    "        X_train = np.array([train_repr[train_sub_date == ss, :].mean(axis=0) for ss in np.unique(train_sub_date)])\n",
    "        X_test = np.array([test_repr[test_sub_date == ss, :].mean(axis=0) for ss in np.unique(test_sub_date)])\n",
    "\n",
    "        # labels for regression and classification task\n",
    "        y_train_total = np.array([train_set[cv]['total_bars'][train_sub_date == ss].mean() for ss in np.unique(train_sub_date)])\n",
    "        y_test_total = np.array([test_set[cv]['total_bars'][test_sub_date == ss].mean() for ss in np.unique(test_sub_date)])\n",
    "        y_train_cl = np.array([train_set[cv]['diag'][train_sub_date == ss][0] for ss in np.unique(train_sub_date)])\n",
    "        y_test_cl = np.array([test_set[cv]['diag'][test_sub_date == ss][0] for ss in np.unique(test_sub_date)])\n",
    "\n",
    "        # train SVR, SVC for regression and classification task\n",
    "        svr_model = train_svr(X_train, y_train_total)\n",
    "        svc_model = train_svc(X_train, y_train_cl)\n",
    "\n",
    "        pred_list.extend(svr_model.predict(X_test))\n",
    "        pred_cl_list.extend(svc_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "        gt_list.extend(y_test_total)\n",
    "        gt_cl_list.extend(y_test_cl)\n",
    "\n",
    "        sub_list.extend([ss for ss in np.unique(test_sub_date)])\n",
    "        diag_list.extend([test_set[cv]['diag'][test_sub_date == ss] for ss in np.unique(test_sub_date)])\n",
    "        age_list.extend([test_set[cv]['age'][test_sub_date == ss][0] for ss in np.unique(test_sub_date)])\n",
    "\n",
    "          \n",
    "        ax = fig_pca.add_subplot(1, 6, cv+1)\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(X_train)\n",
    "        embed_pca = pca.transform(X_test)\n",
    "        pca_1_sign = [1, -1, -1, -1, -1]\n",
    "        pca_2_sign = [1, 1, 1, 1, 1]\n",
    "        embed_pca[:, 0] = embed_pca[:, 0] * pca_1_sign[cv]\n",
    "        embed_pca[:, 1] = embed_pca[:, 1] * pca_2_sign[cv]\n",
    "        cb = ax.scatter(embed_pca[:, 0], embed_pca[:, 1], c=y_test_total, alpha=0.8, cmap='viridis', vmin=0, vmax=25)\n",
    "        embed_pca_list.extend(embed_pca)\n",
    "        ax.set_xlabel(f'PC 1\\n {pca.explained_variance_ratio_[0]*100:.2f} % of Variance')\n",
    "        ax.set_ylabel(f'PC 2\\n {pca.explained_variance_ratio_[1]*100:.2f} % of Variance')\n",
    "        ax.set_title(f'Fold {cv+1}')\n",
    "        ax.set_xlim([-2.2, 2.2])\n",
    "        ax.set_ylim([-2, 2])\n",
    "        embed_pca_each = pca.transform(test_repr)\n",
    "        embed_pca_each[:, 0] = embed_pca_each[:, 0] * pca_1_sign[cv]\n",
    "        embed_pca_each[:, 1] = embed_pca_each[:, 1] * pca_2_sign[cv]\n",
    "\n",
    "       \n",
    "       \n",
    "        \n",
    "        \n",
    "    embed_pca_list = np.array(embed_pca_list)\n",
    "    diag_list = np.array(diag_list, dtype='object')\n",
    "    diag_list_sub = np.array([d[0] for d in diag_list])\n",
    "    age_list = np.array(age_list)\n",
    "    sub_list = np.array(sub_list)\n",
    "    gt_list = np.array(gt_list)\n",
    "    gt_l_list = np.array(gt_l_list)\n",
    "    gt_r_list = np.array(gt_r_list)\n",
    "    gt_arm_list = np.array(gt_arm_list)\n",
    "    gt_cl_list = np.array(gt_cl_list)\n",
    "    pred_list = np.array(pred_list)\n",
    "    pred_l_list = np.array(pred_l_list)\n",
    "    pred_r_list = np.array(pred_r_list)\n",
    "    pred_first_list = np.array(pred_first_list)\n",
    "    pred_second_list = np.array(pred_second_list)\n",
    "    pred_arm_list = np.array(pred_arm_list)\n",
    "    pred_cl_list = np.array(pred_cl_list)\n",
    "    non_lr_list = np.array(non_lr_list)\n",
    "    non_ts_list = np.array(~np.isnan(non_ts_list))\n",
    "\n",
    "\n",
    "    r2, rmse, cross_r, cross_p, long_r, long_p = plot_results(gt_list, pred_list, sub_list, diag_list_sub, 'Total BARS', seg_length)\n",
    "\n",
    "    auc = compute_auc(gt_cl_list, pred_cl_list, diag_list_sub, gt_arm_list)\n",
    "\n",
    "    store_metrics(metrics, r2, rmse, cross_r, cross_p, long_r, long_p, auc)\n",
    "\n",
    "\n",
    "\n",
    "    ax = fig_pca.add_subplot(1, 6, 6)\n",
    "    cb = ax.scatter(embed_pca_list[:, 0], embed_pca_list[:, 1], c=gt_list, alpha=0.8, cmap='viridis', vmin=0, vmax=25)\n",
    "    clb = plt.colorbar(cb)\n",
    "    clb.ax.tick_params(labelsize=8) \n",
    "    clb.ax.set_ylabel('Clinician-scored Total BARS', rotation=270, fontsize=8)\n",
    "    ax.set_xlabel(f'PC 1')\n",
    "    ax.set_ylabel(f'PC 2')\n",
    "    ax.set_title(f'Combined')\n",
    "    ax.set_xlim([-2.2, 2.2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_folder_name + '/pca_{}.pdf'.format(seg_length))    \n",
    "    plt.show() \n",
    "    print('pc1 vs. gt', pearsonr(embed_pca_list[:, 0], gt_list))\n",
    "    print('pc2 vs. gt', pearsonr(embed_pca_list[:, 1], gt_list))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378369e7-7342-47b5-b564-7bf4305f0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Sequence Length (sec)', '$R^2$\\n(Total BARS)', 'RMSE\\n(Total BARS)', 'Cross-sectional correlation $r$\\n(Total BARS)', 'Cross-sectional correlation\\n$p$-value (Total BARS)',\n",
    "                'Longitudianl correlation $r$\\n(Total BARS)', 'Longitudianl correlation\\n$p$-value (Total BARS)',\n",
    "               'Healthy vs. Ataxia AUC']\n",
    "results_all = [list(seg_length_list/freq), list(np.round(metrics['r2'], 2)), list(np.round(metrics['rmse'],2)), list(np.round(metrics['cross_corr'], 2)), list(np.round(metrics['cross_pval'], 3)), \n",
    "               list(np.round(metrics['longitudinal_corr'], 2)), list(np.round(metrics['longitudinal_pval'], 3)), list(np.round(metrics['auc'], 2))]\n",
    "results_all = map(list, zip(*results_all))\n",
    "\n",
    "table = tabulate.tabulate(results_all, tablefmt='html', headers=column_names)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42825d87",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
