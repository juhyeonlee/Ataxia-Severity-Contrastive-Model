{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s9MtD2NtnK5p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23843,
     "status": "ok",
     "timestamp": 1716580125496,
     "user": {
      "displayName": "Juhyeon Lee",
      "userId": "10677926440039300953"
     },
     "user_tz": 240
    },
    "id": "s9MtD2NtnK5p",
    "outputId": "19a3cfc5-6c1d-416c-9576-c04add3fbf60"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from itertools import tee\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import yaml\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import r2_score, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import linregress, pearsonr\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import f as f_oneway\n",
    "\n",
    "from datautils import load_ftn\n",
    "from contrastive_model import ContrastiveModel\n",
    "from utils import init_dl_program\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# to make pdf fonts in vector\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"colorblind\")\n",
    "sns.set_context('paper')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = False  # Turn off histogram borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42533ae-eb59-45df-9840-6532e3322214",
   "metadata": {
    "id": "b42533ae-eb59-45df-9840-6532e3322214"
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "\n",
    "def plot_results(gt_list, res_list, sub_list, diag_list, label_predict, seg_len):\n",
    "    \"\"\"\n",
    "    Generates and visualizes evaluation results for regression downstream tasks.\n",
    "\n",
    "    Parameters:\n",
    "    - gt_list (array-like): clinician scores.\n",
    "    - res_list (array-like): Estimated scores from the model.\n",
    "    - sub_list (array-like): List of subject identifiers and dates.\n",
    "    - diag_list (array-like): Diagnosis information for each subject (1 for ataxia, 0 for healthy).\n",
    "    - label_predict (str): Label indicating the type of score being predicted.\n",
    "    - seg_len (int): Segment length used in the evaluation.\n",
    "\n",
    "    Returns:\n",
    "    - r2 (float): R-squared value for cross-sectional evaluation.\n",
    "    - rmse (float): Root Mean Squared Error for cross-sectional evaluation.\n",
    "    - long_r (float): Pearson correlation coefficient for longitudinal evaluation.\n",
    "    - long_p (float): p-value for longitudinal evaluation.\n",
    "    \"\"\"\n",
    "    # Calculate evaluation metrics (R-squared, RMSE, Pearson correlation)\n",
    "    r2 = r2_score(gt_list, res_list)\n",
    "    rmse = np.sqrt(np.mean(np.square(gt_list - res_list)))\n",
    "    cross_r, cross_p = pearsonr(gt_list, res_list)\n",
    "\n",
    "    # Initialize variables to hold longitudinal analysis data\n",
    "    date_diff, gt_diff, pred_diff, baseline, date_list = [], [], [], [], []\n",
    "    detected = set()\n",
    "\n",
    "    # Iterate over subjects and compute longitudinal differences\n",
    "    for s in sub_list:\n",
    "        date_list.append(np.datetime64('-'.join(s[6:].split('_'))))\n",
    "        subject_id = s[:5]\n",
    "        if subject_id not in detected:\n",
    "            detected.add(subject_id)\n",
    "            sub_same_ind = np.char.find(sub_list, subject_id) != -1\n",
    "            if np.sum(sub_same_ind) >= 2:\n",
    "                for (x1, y1, d1), (x2, y2, d2) in pairwise(zip(gt_list[sub_same_ind], res_list[sub_same_ind], sub_list[sub_same_ind])):\n",
    "                    if diag_list[sub_same_ind][0] != 0:\n",
    "                        gt_diff.append(x2 - x1)\n",
    "                        pred_diff.append(y2 - y1)\n",
    "                        d2_date = np.datetime64('-'.join(d2[6:].split('_')))\n",
    "                        d1_date = np.datetime64('-'.join(d1[6:].split('_')))\n",
    "                        baseline.append(x1)\n",
    "                        date_diff.append((d2_date - d1_date).astype('float'))\n",
    "\n",
    "    gt_diff, pred_diff = np.array(gt_diff), np.array(pred_diff)\n",
    "\n",
    "\n",
    "    # Create subplots for cross-sectional and longitudinal analysis\n",
    "    fig, (fig_cross, fig_long) = plt.subplots(1, 2, figsize=(9, 4))\n",
    "    fig_cross.scatter(gt_list[diag_list == 1], res_list[diag_list == 1], c='b', label='Ataxia')\n",
    "    fig_cross.scatter(gt_list[diag_list == 0], res_list[diag_list == 0], c='g', label='Healthy')\n",
    "    \n",
    "    # Plot cross-sectional evaluation (scatter plot)\n",
    "    min_val, max_val = min(np.min(res_list), np.min(gt_list)), max(np.max(res_list), np.max(gt_list))\n",
    "    res = linregress(gt_list, res_list)\n",
    "    fig_cross.plot([min_val - 0.5, max_val + 0.5], [res.intercept + res.slope * (min_val - 0.5), res.intercept + res.slope * (max_val + 0.5)], 'k--')\n",
    "    fig_cross.plot([min_val - 0.5, max_val + 0.5], [min_val - 0.5, max_val + 0.5], 'k')\n",
    "    fig_cross.set_xlabel(f'Clinician-scored {label_predict}')\n",
    "    fig_cross.set_ylabel(f'Estimated {label_predict}')\n",
    "    fig_cross.axis('square')\n",
    "    fig_cross.legend()\n",
    "\n",
    "    # Plot longitudinal evaluation (scatter plot)\n",
    "    min_y, max_y = min(np.min(gt_diff), np.min(pred_diff)), max(np.max(gt_diff), np.max(pred_diff))\n",
    "    cb = fig_long.scatter(gt_diff, pred_diff, c=baseline, cmap='viridis', vmin=np.min(gt_list), vmax=np.max(gt_list))\n",
    "    res_diff = linregress(gt_diff, pred_diff)\n",
    "    fig_long.plot([min_y - 0.5, max_y + 0.5], [res_diff.intercept + res_diff.slope * (min_y - 0.5), res_diff.intercept + res_diff.slope * (max_y + 0.5)], 'k--')\n",
    "    fig_long.plot([min_y - 0.5, max_y + 0.5], [min_y - 0.5, max_y + 0.5], 'k')\n",
    "    fig_long.set_xlabel(f'Diff. Clinician-scored {label_predict}')\n",
    "    fig_long.set_ylabel(f'Diff. Estimated {label_predict}')\n",
    "    fig_long.axvline(0, linestyle='--', color='r')\n",
    "    fig_long.axhline(0, linestyle='--', color='r')\n",
    "    clb = plt.colorbar(cb, ax=fig_long)\n",
    "    clb.ax.tick_params(labelsize=8)\n",
    "    clb.set_label('Clinician-scored Total BARS (Baseline)', rotation=270, fontsize=8, labelpad=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate and print longitudinal Pearson correlation\n",
    "    long_r, long_p = pearsonr(gt_diff, pred_diff)\n",
    "    print(f'Cross-Sectional R2: {r2:.2f}, RMSE: {rmse:.2f}, Pearson r: {cross_r:.2f}, p: {cross_p:.3f} /  Longitudinal r: {long_r:.2f}, p: {long_p:.3f}')\n",
    "\n",
    "    return r2, rmse, cross_r, cross_p, long_r, long_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'r2': [],\n",
    "    'rmse': [],\n",
    "    'cross_corr': [],\n",
    "    'cross_pval': [],\n",
    "    'longitudinal_corr': [],\n",
    "    'longitudinal_pval': [],\n",
    "    'auc': []\n",
    "}\n",
    "\n",
    "\n",
    "def store_metrics(metrics, r2, rmse, cross_r, cross_p, long_r, long_p, auc):\n",
    "    metrics['r2'].append(r2)\n",
    "    metrics['rmse'].append(rmse)\n",
    "    metrics['cross_corr'].append(cross_r)\n",
    "    metrics['cross_pval'].append(cross_p)\n",
    "    metrics['longitudinal_corr'].append(long_r)\n",
    "    metrics['longitudinal_pval'].append(long_p)\n",
    "    metrics['auc'].append(auc)\n",
    "\n",
    "def compute_auc(gt_cl_list, pred_cl_list, diag_list, gt_arm_list):\n",
    "    # compute ROC curve and AUC for all participants\n",
    "    fpr, tpr, _ = roc_curve(gt_cl_list, pred_cl_list)\n",
    "    auc = roc_auc_score(gt_cl_list, pred_cl_list)\n",
    "    \n",
    "    # compute ROC curve and AUC for healthy vs. individuals with ataxia and a BARS finger-to-nose subscore of 0\n",
    "    mask_arm_z = np.logical_or(np.logical_and(diag_list != 0, gt_arm_list == 0), diag_list == 0)\n",
    "    fpr_armz, tpr_armz, _ = roc_curve(gt_cl_list[mask_arm_z], \n",
    "                                              pred_cl_list[mask_arm_z])\n",
    "    auc_arm_z = roc_auc_score(gt_cl_list[mask_arm_z], pred_cl_list[mask_arm_z])\n",
    "    fig_cl = plt.figure(figsize=(8, 4))\n",
    "    ax = fig_cl.add_subplot(1, 2, 1)\n",
    "    ax.plot(fpr, tpr, label=\"AUC = {:.2}\".format(auc))\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    ax = fig_cl.add_subplot(1, 2, 2)\n",
    "    ax.plot(fpr_armz, tpr_armz, label=\"AUC = {:.2}\".format(auc_arm_z))\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return auc\n",
    "\n",
    "\n",
    "def plot_pca(ax, X_train, X_test, y_test_total):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X_train)\n",
    "    embed_pca = pca.transform(X_test)\n",
    "    pca_1_sign = [1, -1, -1, -1, -1]\n",
    "    pca_2_sign = [1, 1, 1, 1, 1]\n",
    "    embed_pca[:, 0] = embed_pca[:, 0] * pca_1_sign[cv]\n",
    "    embed_pca[:, 1] = embed_pca[:, 1] * pca_2_sign[cv]\n",
    "    cb = ax.scatter(embed_pca[:, 0], embed_pca[:, 1], c=y_test_total, alpha=0.8, cmap='viridis', vmin=0, vmax=25)\n",
    "    ax.set_xlabel(f'PC 1\\n {pca.explained_variance_ratio_[0]*100:.2f} % of Variance')\n",
    "    ax.set_ylabel(f'PC 2\\n {pca.explained_variance_ratio_[1]*100:.2f} % of Variance')\n",
    "    ax.set_title(f'Fold {cv+1}')\n",
    "    ax.set_xlim([-2.2, 2.2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    return embed_pca\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svr(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a Support Vector Regression model\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (array-like): Training data\n",
    "    - y_train (array-like): Target values representing clinician-scored BARS\n",
    "\n",
    "    Returns:\n",
    "    - fit_model: Trained SVR model fitted on the provided training data.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(SVR(), {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \n",
    "                                       'kernel': ['rbf'], 'gamma': ['scale']}, cv=10, n_jobs=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    fit_model = best_model.fit(X_train, y_train)\n",
    "    return fit_model\n",
    "\n",
    "\n",
    "def train_svc(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a Support Vector Classification model\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (array-like): Training data\n",
    "    - y_train (array-like): Target values representing clinician-scored BARS\n",
    "\n",
    "    Returns:\n",
    "    - fit_model: Trained SVC model fitted on the provided training data.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(SVC(probability=True), {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \n",
    "                                                       'kernel': ['rbf'], 'gamma': ['scale']}, cv=10, n_jobs=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    fit_model = best_model.fit(X_train, y_train)\n",
    "    return fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52bd44-ac47-4a7c-9bf6-164344b3d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config.yaml to read training parameters\n",
    "with open('config.yaml', 'r') as file:\n",
    "        cfg = yaml.safe_load(file)\n",
    "\n",
    "run_name = cfg.get('run_name', 'ftn_no_rotate')\n",
    "gpu = cfg.get('gpu', '0')\n",
    "batch_size = cfg.get('batch_size', 32)\n",
    "lr = cfg.get('lr', 0.001)\n",
    "repr_dims = cfg.get('repr_dims', 320)\n",
    "epochs = cfg.get('epochs', 200)\n",
    "seed = cfg.get('seed', 42)\n",
    "max_threads = cfg.get('max_threads', 8)\n",
    "freq = cfg.get('freq', 128)\n",
    "seg_length_sec = cfg.get('seg_length_sec', 10)\n",
    "cv_num = cfg.get('cv_num', 5)\n",
    "data_folder = cfg.get('data_folder', 'FNT_data')\n",
    "seg_length = freq * seg_length_sec\n",
    "\n",
    "# Load trained models with different segment lengths\n",
    "model_folder_name = './checkpoints'\n",
    "\n",
    "seg_length_list = []\n",
    "file_list = np.array(os.listdir(model_folder_name))\n",
    "for files in file_list:\n",
    "    if \".\" not in files:\n",
    "        seg_length_list.append(int(files.split('_')[-1]))\n",
    "    else:\n",
    "        seg_length_list.append(np.nan)\n",
    "seg_length_list = np.array(seg_length_list)\n",
    "file_list = file_list[~np.isnan(seg_length_list)]\n",
    "seg_length_list = seg_length_list[~np.isnan(seg_length_list)]\n",
    "seg_length_idx = np.argsort(seg_length_list)\n",
    "seg_length_list = seg_length_list[seg_length_idx]\n",
    "file_list = file_list[seg_length_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e261dc-cd2f-48bf-9384-b484b69636f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "15iR3jYW0jKQ8dCWI1Gt__TtInN0v8FJd"
    },
    "executionInfo": {
     "elapsed": 811683,
     "status": "ok",
     "timestamp": 1716435766102,
     "user": {
      "displayName": "Juhyeon Lee",
      "userId": "10677926440039300953"
     },
     "user_tz": 240
    },
    "id": "e0e261dc-cd2f-48bf-9384-b484b69636f9",
    "outputId": "f907b0c2-2e5a-4314-9152-5b77bd19564b"
   },
   "outputs": [],
   "source": [
    "\n",
    "for files in file_list:\n",
    "    seg_length = int(files.split('_')[-1])\n",
    "    seg_length_sec = seg_length / freq\n",
    "    print(f\"Segment Length (s): {int(seg_length_sec)}\")\n",
    "    if seg_length_sec > 20:\n",
    "        break\n",
    "\n",
    "    # Load training dataset\n",
    "    device = init_dl_program(gpu, seed=seed, max_threads=max_threads, deterministic=False)\n",
    "    train_set = load_ftn(data_folder, cv_num, seg_length, is_train=True)\n",
    "\n",
    "    # Load test dataset\n",
    "    device = init_dl_program(gpu, seed=seed, max_threads=max_threads, deterministic=False)\n",
    "    test_set = load_ftn(data_folder, cv_num, seg_length, is_train=False, overlap_test=seg_length)\n",
    "\n",
    "    sub_list, diag_list, gt_list, gt_arm_list, gt_cl_list, pred_list, pred_cl_list = [], [], [], [], [], [], []\n",
    "    embed_pca_list, age_list = [], []\n",
    "    \n",
    "    # To visualize the feature embeddings using PCA (for all folds)\n",
    "    fig_pca = plt.figure(figsize = (18, 3))\n",
    "    \n",
    "    # five-fold cross-validation\n",
    "    for cv in range(cv_num):\n",
    "        # Load the trained model\n",
    "        model = ContrastiveModel(input_dims=train_set[cv]['data'].shape[-1], device=device)\n",
    "        model.load(os.path.join(model_folder_name, files, f'model_{cv}.pkl'))\n",
    "\n",
    "        # Encode representations\n",
    "        train_sub_date, test_sub_date = train_set[cv]['sub_date'], test_set[cv]['sub_date']\n",
    "        train_repr = model.encode(train_set[cv]['data'], encoding_window='full_series', batch_size=128)\n",
    "        test_repr = model.encode(test_set[cv]['data'], encoding_window='full_series', batch_size=128)\n",
    "\n",
    "        # Aggregate represensetions for each subject and session\n",
    "        X_train = np.array([train_repr[train_sub_date == ss, :].mean(axis=0) for ss in np.unique(train_sub_date)])\n",
    "        X_test = np.array([test_repr[test_sub_date == ss, :].mean(axis=0) for ss in np.unique(test_sub_date)])\n",
    "\n",
    "        # Labels for regression and classification task\n",
    "        y_train_total = np.array([train_set[cv]['total_bars'][train_sub_date == ss].mean() for ss in np.unique(train_sub_date)])\n",
    "        y_test_total = np.array([test_set[cv]['total_bars'][test_sub_date == ss].mean() for ss in np.unique(test_sub_date)])\n",
    "        y_train_cl = np.array([train_set[cv]['diag'][train_sub_date == ss][0] for ss in np.unique(train_sub_date)])\n",
    "        y_test_cl = np.array([test_set[cv]['diag'][test_sub_date == ss][0] for ss in np.unique(test_sub_date)])\n",
    "        y_test_arm = np.array([test_set[cv]['arm_bars'][test_sub_date == ss].mean() for ss in np.unique(test_sub_date)])\n",
    "\n",
    "        # Train SVR, SVC for regression and classification task\n",
    "        svr_model = train_svr(X_train, y_train_total)\n",
    "        svc_model = train_svc(X_train, y_train_cl)\n",
    "\n",
    "        pred_list.extend(svr_model.predict(X_test))\n",
    "        pred_cl_list.extend(svc_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "        gt_list.extend(y_test_total)\n",
    "        gt_cl_list.extend(y_test_cl)\n",
    "        gt_arm_list.extend(y_test_arm)\n",
    "\n",
    "        sub_list.extend([ss for ss in np.unique(test_sub_date)])\n",
    "        diag_list.extend([test_set[cv]['diag'][test_sub_date == ss][0] for ss in np.unique(test_sub_date)])\n",
    "        age_list.extend([test_set[cv]['age'][test_sub_date == ss][0] for ss in np.unique(test_sub_date)])\n",
    "        \n",
    "        # Visualize the learned feature embeddings using PCA\n",
    "        ax = fig_pca.add_subplot(1, cv_num + 1, cv+1)\n",
    "        embed_pca = plot_pca(ax, X_train, X_test, y_test_total)     \n",
    "        embed_pca_list.extend(embed_pca)\n",
    "\n",
    "    embed_pca_list, diag_list, sub_list, gt_list, gt_cl_list, gt_arm_list, pred_list, pred_cl_list = map(np.array,\n",
    "        [embed_pca_list, diag_list, sub_list, gt_list, gt_cl_list, gt_arm_list, pred_list, pred_cl_list])\n",
    "\n",
    "    ax = fig_pca.add_subplot(1, cv_num + 1, cv_num + 1)\n",
    "    cb = ax.scatter(embed_pca_list[:, 0], embed_pca_list[:, 1], c=gt_list, alpha=0.8, cmap='viridis', vmin=0, vmax=25)\n",
    "    clb = plt.colorbar(cb)\n",
    "    clb.ax.tick_params(labelsize=8) \n",
    "    clb.ax.set_ylabel('Clinician-scored Total BARS', rotation=270, fontsize=8)\n",
    "    ax.set_xlabel(f'PC 1')\n",
    "    ax.set_ylabel(f'PC 2')\n",
    "    ax.set_title(f'Combined')\n",
    "    ax.set_xlim([-2.2, 2.2])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "    # Plot the cross-sectional and longitudinal regression results\n",
    "    r2, rmse, cross_r, cross_p, long_r, long_p = plot_results(gt_list, pred_list, sub_list, diag_list, 'Total BARS', seg_length)\n",
    "\n",
    "    # Plot the classification results\n",
    "    auc = compute_auc(gt_cl_list, pred_cl_list, diag_list, gt_arm_list)\n",
    "\n",
    "    # Store evaluated metrics\n",
    "    store_metrics(metrics, r2, rmse, cross_r, cross_p, long_r, long_p, auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378369e7-7342-47b5-b564-7bf4305f0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    'Sequence Length (sec)', '$R^2$ (Total BARS)', 'RMSE (Total BARS)',\n",
    "    'Cross-sectional r (Total BARS)', 'Cross-sectional p-value (Total BARS)',\n",
    "    'Longitudinal r (Total BARS)', 'Longitudinal p-value (Total BARS)',\n",
    "    'AUC (Healthy vs. Ataxia)'\n",
    "]\n",
    "\n",
    "results_all = zip(\n",
    "    seg_length_list / freq,\n",
    "    np.round(metrics['r2'], 2),\n",
    "    np.round(metrics['rmse'], 2),\n",
    "    np.round(metrics['cross_corr'], 2),\n",
    "    np.round(metrics['cross_pval'], 3),\n",
    "    np.round(metrics['longitudinal_corr'], 2),\n",
    "    np.round(metrics['longitudinal_pval'], 3),\n",
    "    np.round(metrics['auc'], 2)\n",
    ")\n",
    "\n",
    "table = tabulate.tabulate(results_all, tablefmt='html', headers=column_names)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb256510-73ec-45eb-9af0-d01124ac9eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
